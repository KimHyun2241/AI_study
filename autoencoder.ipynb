{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오토인코더\n",
    "- **인코더**의 역할을 맡아 각 의류 아이템을 옷장의 특정 위치로 이동하며 이 과정을 **인코딩**이라 한다.\n",
    "- 브라이언은 **디코더**의 역할을 맡아 옷장의 한 위치를 받아 해당 아이템을 다시 생성하려고 시도한다. 이 과정을 **디코딩**이라 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패션 MNIST 데이터셋 로드\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def preprocess(imgs):\n",
    "    imgs = imgs.astype(\"float32\") / 255.0\n",
    "    imgs = np.pad(imgs, ((0,0), (2,2), (2,2)), constant_values=0.0)\n",
    "    imgs = np.expand_dims(imgs, -1)\n",
    "    return imgs\n",
    "\n",
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원본 이미지는 28X28 크기 흑백 이미지(픽셀 값은 0~255)이므로 픽셀 값을 0~1 사이로 조정해야 한다.\n",
    "- 또한 위 예제처럼 이미지가 신경망을 통과할 때 텐서 크기를 쉽게 조작할 수있도록 각 이미지에 패딩을 추가하여 32X32 크기로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 인코더의 Input 층(이미지)을 정의\n",
    "encoder_input = layers.Input(\n",
    "\tshape=(32, 32,1), name = \"encoder_input\"\n",
    ")\n",
    "#2 순서대로 Conv2D 층을 쌓는다.\n",
    "x = layers.Conv2D(32, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(\n",
    "\tencoder_input\n",
    ")\n",
    "x = layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(x)\n",
    "x = layers.Conv2D(128, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(x)\n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "#3 마지막 합성곱 층의 출력을 벡터로 펼침\n",
    "x = layers.Flatten()(x)\n",
    "#4 이 벡터를 2D 임베딩에 해당하는 Dense 층에 연결\n",
    "encoder_output = layers.Dense(2, name=\"encoder_output\")(x)\n",
    "\n",
    "#5 케라스 Model 클래스로 인코더를 정의. 이 모델은 입력 이미지를 받아 이를 2D 임베딩에 인코딩한다.\n",
    "encoder = models.Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " encoder_output (Dense)      (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96770 (378.01 KB)\n",
      "Trainable params: 96770 (378.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 디코더의 Input층 (임베딩)을 정의\n",
    "decoder_input = layers.Input(shape=(2,), name=\"decoder_input\")\n",
    "\n",
    "#2 입력을 Dense 층에 연결\n",
    "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "#3 첫 번째 Conv2Dtranspose 층에 입력으로 주입할 수 있도록 Reshape 층의 벡터의 크기를 바꾼다.\n",
    "x = layers.Reshape(shape_before_flattening)(x)\n",
    "#4 Conv2DTranspose 층을 연속으로 쌓음\n",
    "x = layers.Conv2DTranspose(128, (3,3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(64, (3,3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3,3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "decoder_output = layers.Conv2D(\n",
    "\t1,\n",
    "\t(3,3),\n",
    "\tstrides = 1,\n",
    "\tactivation=\"sigmoid\",\n",
    "\tpadding=\"same\",\n",
    "\tname=\"decoder_output\"\n",
    ")(x)\n",
    "\n",
    "#5 케라스 Model 클래스로 디코더를 정의\n",
    "#5 이 모델은 잠재 공간의 임베딩을 받아 원본 이밎 도메인으로 디코\n",
    "decoder = models.Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              6144      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 8, 8, 128)         147584    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 16, 16, 64)        73792     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 32, 32, 32)        18464     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " decoder_output (Conv2D)     (None, 32, 32, 1)         289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 246273 (962.00 KB)\n",
      "Trainable params: 246273 (962.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " encoder_output (Dense)      (None, 2)                 4098      \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 32, 32, 1)         246273    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343043 (1.31 MB)\n",
      "Trainable params: 343043 (1.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#1 케라스 Model 클래스로 완전한 오토인코더를 정의\n",
    "#1 이 모델은 이미지를 입력으로 받아 인코더와 디코더를 통과시켜 원본 이미지의 재구성을 생성\n",
    "autoencoder = models.Model(encoder_input, decoder(encoder_output))\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "language_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
